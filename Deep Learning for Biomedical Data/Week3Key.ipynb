{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlKfUT1M3yHv"
      },
      "source": [
        "#Week 3 Lab: Convolutional Neural Networks\n",
        "\n",
        "In this example, we will use Keras to develop convolutional neural network models.\n",
        "\n",
        "Here's an example of transfer learning for image classification. We replace the last layer of inceptionV3 with a custom classification layer, which allows user-defined categories not present in the ImageNet challenge.\n",
        "In this example, we are going to use ImageNet models to classify dogs and cats (https://www.kaggle.com/c/dogs-vs-cats). A subset of the images could be found at https://www.dropbox.com/sh/sun8qns27gb9hkc/AAAySZPWAioQM6GQIor-xKtZa?dl=0.\n",
        "\n",
        "Tailored from examples in the Keras documentation: https://keras.io/\n",
        "\n",
        "\n",
        "\n",
        "Kun-Hsing Yu\n",
        "\n",
        "Updated and simplified on April 3, 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOQPyXcF3GhM"
      },
      "outputs": [],
      "source": [
        "# import tensorflow backend and keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# using inception_V3 in this example, also works on other pre-trained models \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras import backend as K\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sETZUq5VdEjp"
      },
      "source": [
        "### Download the example images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJTy6QMCdG8P",
        "outputId": "844d040a-847a-409e-e02e-79b21e57f421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-03 23:30:38--  https://www.dropbox.com/s/v4vxu296ad9h69y/train.tar\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.69.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.69.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/v4vxu296ad9h69y/train.tar [following]\n",
            "--2023-04-03 23:30:39--  https://www.dropbox.com/s/raw/v4vxu296ad9h69y/train.tar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc96859d792f8c5a22e7a4fccd26.dl.dropboxusercontent.com/cd/0/inline/B5gP778yqwzfB1zIvZt3r6xAxfatMxpgMRb3fBM7ZEfkPtjrUUIYVUneGPwmbzrFs_GGQmGm-VRrsFMBs-hzo0y6K5mt3kLVhc8o9hUjS6IOY6-KwoWzMUQRHz0wsk8gyNc4WDjKsfpWM4W_NEV6_jD7_tT0RLVTZKGP7y42mUuI2g/file# [following]\n",
            "--2023-04-03 23:30:40--  https://uc96859d792f8c5a22e7a4fccd26.dl.dropboxusercontent.com/cd/0/inline/B5gP778yqwzfB1zIvZt3r6xAxfatMxpgMRb3fBM7ZEfkPtjrUUIYVUneGPwmbzrFs_GGQmGm-VRrsFMBs-hzo0y6K5mt3kLVhc8o9hUjS6IOY6-KwoWzMUQRHz0wsk8gyNc4WDjKsfpWM4W_NEV6_jD7_tT0RLVTZKGP7y42mUuI2g/file\n",
            "Resolving uc96859d792f8c5a22e7a4fccd26.dl.dropboxusercontent.com (uc96859d792f8c5a22e7a4fccd26.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc96859d792f8c5a22e7a4fccd26.dl.dropboxusercontent.com (uc96859d792f8c5a22e7a4fccd26.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B5j98Taxzz0IgQ7mBd8GndRaratTvs_JLkNzrGQ4gJHV0dzdSbK60iw8vTyZ9TOvZiVVTKcn6ufDZig7vgCCu0qTmYiMK6cyM_2LQqUKRJZhqpxKwZAamF564ERuHkYVqi87ACU4OpGF4yNq9Cl0IJ_swjDJbPEvb8qObn-6DW-fusS2c0zJPyI_DeiUHqLgIkXgb8yL4sJIgPMLHni7oktRy1R6X_G6-Q8zLO-qt2iEBKManXlVevTF-Csdy8lOTgAdUAjp0GkEFTKm88XSQAWXrebjq23l8MQh-hFhAsqbYdBWrmSCpXs9fPuKclRYu90Rl54knRBRY8zw619wAtOea83Vs9Nvixm3gaotBzpURwa10nu08kJaAKNkHUDOarI0i2U1bTmxfu3JJatQNeFdpoI90YO2nZC7YgE6JB-O8Q/file [following]\n",
            "--2023-04-03 23:30:41--  https://uc96859d792f8c5a22e7a4fccd26.dl.dropboxusercontent.com/cd/0/inline2/B5j98Taxzz0IgQ7mBd8GndRaratTvs_JLkNzrGQ4gJHV0dzdSbK60iw8vTyZ9TOvZiVVTKcn6ufDZig7vgCCu0qTmYiMK6cyM_2LQqUKRJZhqpxKwZAamF564ERuHkYVqi87ACU4OpGF4yNq9Cl0IJ_swjDJbPEvb8qObn-6DW-fusS2c0zJPyI_DeiUHqLgIkXgb8yL4sJIgPMLHni7oktRy1R6X_G6-Q8zLO-qt2iEBKManXlVevTF-Csdy8lOTgAdUAjp0GkEFTKm88XSQAWXrebjq23l8MQh-hFhAsqbYdBWrmSCpXs9fPuKclRYu90Rl54knRBRY8zw619wAtOea83Vs9Nvixm3gaotBzpURwa10nu08kJaAKNkHUDOarI0i2U1bTmxfu3JJatQNeFdpoI90YO2nZC7YgE6JB-O8Q/file\n",
            "Reusing existing connection to uc96859d792f8c5a22e7a4fccd26.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46827520 (45M) [application/x-tar]\n",
            "Saving to: ‘train.tar’\n",
            "\n",
            "train.tar           100%[===================>]  44.66M  16.0MB/s    in 2.8s    \n",
            "\n",
            "2023-04-03 23:30:44 (16.0 MB/s) - ‘train.tar’ saved [46827520/46827520]\n",
            "\n",
            "--2023-04-03 23:30:44--  https://www.dropbox.com/s/hp25txiaxbdfvv0/validation.tar\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.69.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.69.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/hp25txiaxbdfvv0/validation.tar [following]\n",
            "--2023-04-03 23:30:45--  https://www.dropbox.com/s/raw/hp25txiaxbdfvv0/validation.tar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc270bf176632a3049dea354f63d.dl.dropboxusercontent.com/cd/0/inline/B5gpeBElG8abOj9UAePfSltYMEG6the95yyBhHMY2Z4ffvV3iRMuWt1OPQLJg3Gv_BdND2BVwLrp2V65SMsmK82PLHIT2Q0W99XdE-s6qGgMfyXsm3QlWio9OWoQtHOefCe4MBsV15LdXJ0GOBSRHH1Na78sY90kMZA7_6kz1hQgvg/file# [following]\n",
            "--2023-04-03 23:30:46--  https://uc270bf176632a3049dea354f63d.dl.dropboxusercontent.com/cd/0/inline/B5gpeBElG8abOj9UAePfSltYMEG6the95yyBhHMY2Z4ffvV3iRMuWt1OPQLJg3Gv_BdND2BVwLrp2V65SMsmK82PLHIT2Q0W99XdE-s6qGgMfyXsm3QlWio9OWoQtHOefCe4MBsV15LdXJ0GOBSRHH1Na78sY90kMZA7_6kz1hQgvg/file\n",
            "Resolving uc270bf176632a3049dea354f63d.dl.dropboxusercontent.com (uc270bf176632a3049dea354f63d.dl.dropboxusercontent.com)... 162.125.7.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc270bf176632a3049dea354f63d.dl.dropboxusercontent.com (uc270bf176632a3049dea354f63d.dl.dropboxusercontent.com)|162.125.7.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B5jxKxmuXP2lyjFSM-Ss3QZj55km5EIbuBXsbFMu7LHvXBfZ1WiOsj4cryp3GCF0IVJbRN0Yt-dKLZyS6XVl9j24AdiNJdUwJ0Rat1YP4QTrsWzVLNX5D6P4sZuiD0XeYpIW7yvF8aRJ3qyhalvIOQ3Y039a9YwCsP8Q9SHYjd13OIdnrFATTLto5ULcDBkUuib4WrcqWcJTDJZWCn5zBnc7kbdrv2CUVbm5kwpuSeaoC1D2wKzwkFVRH4fq1e1GhkoXs6DGhOqSRprCjEJRLNnwMh5QpPwz1wnW_PQ3lwvAJpaYZvCKRJueB14yQA94FDUodBStVEf6fsupPDeZwi6yUKTTpNB7sXhkOoIz6sr25kTm8wUwcmBSbS9RmGCnr8kzb6wVQOC9KOUCxk4RvH22HfoqDe2p9N_kPTcEmFtVBQ/file [following]\n",
            "--2023-04-03 23:30:47--  https://uc270bf176632a3049dea354f63d.dl.dropboxusercontent.com/cd/0/inline2/B5jxKxmuXP2lyjFSM-Ss3QZj55km5EIbuBXsbFMu7LHvXBfZ1WiOsj4cryp3GCF0IVJbRN0Yt-dKLZyS6XVl9j24AdiNJdUwJ0Rat1YP4QTrsWzVLNX5D6P4sZuiD0XeYpIW7yvF8aRJ3qyhalvIOQ3Y039a9YwCsP8Q9SHYjd13OIdnrFATTLto5ULcDBkUuib4WrcqWcJTDJZWCn5zBnc7kbdrv2CUVbm5kwpuSeaoC1D2wKzwkFVRH4fq1e1GhkoXs6DGhOqSRprCjEJRLNnwMh5QpPwz1wnW_PQ3lwvAJpaYZvCKRJueB14yQA94FDUodBStVEf6fsupPDeZwi6yUKTTpNB7sXhkOoIz6sr25kTm8wUwcmBSbS9RmGCnr8kzb6wVQOC9KOUCxk4RvH22HfoqDe2p9N_kPTcEmFtVBQ/file\n",
            "Reusing existing connection to uc270bf176632a3049dea354f63d.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4648960 (4.4M) [application/x-tar]\n",
            "Saving to: ‘validation.tar’\n",
            "\n",
            "validation.tar      100%[===================>]   4.43M  3.30MB/s    in 1.3s    \n",
            "\n",
            "2023-04-03 23:30:49 (3.30 MB/s) - ‘validation.tar’ saved [4648960/4648960]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/v4vxu296ad9h69y/train.tar\n",
        "!wget https://www.dropbox.com/s/hp25txiaxbdfvv0/validation.tar\n",
        "!tar -xf train.tar\n",
        "!tar -xf validation.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_jWjR8BjBWh"
      },
      "source": [
        "## Quiz Question 1\n",
        "What's in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_ifn3zbiSzc",
        "outputId": "54afbb05-1ec9-468d-cae6-5e5498269eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  train  train.tar  validation  validation.tar\n",
            "##### In train/ #####\n",
            "cats  dogs\n",
            "##### In validation/ #####\n",
            "cats  dogs\n",
            "##### In train/cats/ #####\n",
            "cat.1000.jpg\n",
            "cat.1001.jpg\n",
            "cat.1002.jpg\n",
            "cat.1003.jpg\n",
            "cat.1004.jpg\n",
            "cat.1005.jpg\n",
            "cat.1006.jpg\n",
            "cat.1007.jpg\n",
            "cat.1008.jpg\n",
            "cat.1009.jpg\n",
            "##### In train/dogs/ #####\n",
            "dog.1000.jpg\n",
            "dog.1001.jpg\n",
            "dog.1002.jpg\n",
            "dog.1003.jpg\n",
            "dog.1004.jpg\n",
            "dog.1005.jpg\n",
            "dog.1006.jpg\n",
            "dog.1007.jpg\n",
            "dog.1008.jpg\n",
            "dog.1009.jpg\n",
            "##### In validation/cats/ #####\n",
            "cat.100.jpg\n",
            "cat.101.jpg\n",
            "cat.102.jpg\n",
            "cat.103.jpg\n",
            "cat.104.jpg\n",
            "cat.105.jpg\n",
            "cat.106.jpg\n",
            "cat.107.jpg\n",
            "cat.108.jpg\n",
            "cat.109.jpg\n",
            "##### In validation/dogs/ #####\n",
            "dog.100.jpg\n",
            "dog.101.jpg\n",
            "dog.102.jpg\n",
            "dog.103.jpg\n",
            "dog.104.jpg\n",
            "dog.105.jpg\n",
            "dog.106.jpg\n",
            "dog.107.jpg\n",
            "dog.108.jpg\n",
            "dog.109.jpg\n"
          ]
        }
      ],
      "source": [
        "# Your answer here\n",
        "############################################################\n",
        "!ls \n",
        "!echo \"##### In train/ #####\"\n",
        "!ls train\n",
        "!echo \"##### In validation/ #####\"\n",
        "!ls validation\n",
        "!echo \"##### In train/cats/ #####\"\n",
        "!ls train/cats/ |head\n",
        "!echo \"##### In train/dogs/ #####\"\n",
        "!ls train/dogs/ |head\n",
        "!echo \"##### In validation/cats/ #####\"\n",
        "!ls validation/cats/ |head\n",
        "!echo \"##### In validation/dogs/ #####\"\n",
        "!ls validation/dogs/ |head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBxszY9HcViA"
      },
      "source": [
        "## Quiz Question 2\n",
        "Please load the InceptionV3 model as the base model.\n",
        "\n",
        "Hint: https://keras.io/applications/#fine-tune-inceptionv3-on-a-new-set-of-classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NmnI-HPcUyk",
        "outputId": "15e5a831-9df2-4fea-e9f0-a2432381a916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Your codes here\n",
        "############################################################\n",
        "\n",
        "# in this example, we will use inception V3 as the base model.\n",
        "# you will have the chance to try a number of ImageNet models in Assignment 2.\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ65MxHofiF1"
      },
      "source": [
        "## Quiz Question 3\n",
        "Add a logistic layer for binary classification\n",
        "\n",
        "Hint: https://keras.io/applications/#fine-tune-inceptionv3-on-a-new-set-of-classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2w0qQ9bfeQ2"
      },
      "outputs": [],
      "source": [
        "# Your codes here\n",
        "############################################################\n",
        "\n",
        "# get the output of the base model\n",
        "x = base_model.output\n",
        "# add a 2D global average pooling layer\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# add a layer for binary classification\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# define the model to be trained\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcDQ5jlM7w0P"
      },
      "source": [
        "###To fix the layers in the base model.\n",
        "It is useful if you don't have a lot of data. If you have sufficient data, you can also backpropagate into the layers in the base model after the last layers were trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH7Pydb53tVl"
      },
      "outputs": [],
      "source": [
        "# only train the added layers, but not the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COS1CTLpcemO"
      },
      "source": [
        "## Quiz Question 4\n",
        "Compile the model.\n",
        "Why do we need to compile the model?\n",
        "\n",
        "Hint: https://keras.io/models/model/#compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaUlx3Ch3w0y"
      },
      "outputs": [],
      "source": [
        "# Your answer and codes here\n",
        "############################################################\n",
        "# in Keras, we need to compile the model to configure the optimizer, loss function, etc.\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc3AI-pN63g_"
      },
      "source": [
        "###Define data pre-processing methods for the training and the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtFLOiBz7A0P"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# define the batch size, if there is sufficient GPU memory, you can increase the batch size\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8JcB3Acqzs"
      },
      "source": [
        "###Define the methods to load the image from directories\n",
        "Please put your training data under the 'train' directory, with images with label \"0\" under 'train/0' and images with label \"1\" under 'train/1'; put validation data under the 'validation' directory, with images with label \"0\" under 'validation/0' and images with label \"1\" under 'validation/1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNhGV49ncsz_",
        "outputId": "43116094-cac2-436a-9720-aeb79817d9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'train',  # the directory for the training data\n",
        "        target_size=(150, 150),  # resize the input images to accommodate the model\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'validation', # the directory for the validation data\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GwJeQhf5C6S"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1LI2wQN3xVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48461f76-ee8a-4243-9e82-adad516f5bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "125/125 [==============================] - 32s 150ms/step - loss: 0.2137 - accuracy: 0.9130 - val_loss: 0.1143 - val_accuracy: 0.9479\n",
            "Epoch 2/5\n",
            "125/125 [==============================] - 16s 131ms/step - loss: 0.1299 - accuracy: 0.9490 - val_loss: 0.1358 - val_accuracy: 0.9375\n",
            "Epoch 3/5\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.1050 - accuracy: 0.9590 - val_loss: 0.1366 - val_accuracy: 0.9479\n",
            "Epoch 4/5\n",
            "125/125 [==============================] - 17s 137ms/step - loss: 0.1081 - accuracy: 0.9535 - val_loss: 0.1402 - val_accuracy: 0.9427\n",
            "Epoch 5/5\n",
            "125/125 [==============================] - 17s 138ms/step - loss: 0.0959 - accuracy: 0.9640 - val_loss: 0.1317 - val_accuracy: 0.9583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f713a9ae670>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# please change nTraining to the number of training cases and nValidation to the number of validation cases\n",
        "nTraining = 2000\n",
        "nValidation = 200\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=nTraining // batch_size,\n",
        "        epochs=5,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=nValidation // batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFNSLDFvd6xh"
      },
      "source": [
        "## Quiz Question 5\n",
        "How to accelerate the training process?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jjcUpcwd_7w"
      },
      "outputs": [],
      "source": [
        "# Your answer here\n",
        "############################################################\n",
        "# Runtime -> Change runtime type -> Hardware accelerator -> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIi0qZ_vc0dO"
      },
      "source": [
        "### Generate predictions on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnYjzqHd5ZNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f383725-dfc0-4694-9128-2a943eae23ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 images belonging to 2 classes.\n",
            "2/2 [==============================] - 4s 20ms/step\n"
          ]
        }
      ],
      "source": [
        "generator = test_datagen.flow_from_directory(\n",
        "        'validation',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=100,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "probabilities = model.predict(generator, steps=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuPtaAYc7Q8z"
      },
      "source": [
        "### Generate the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0kotVW96u-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45582fd-d03a-40b3-eae7-8035b95a6c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[92  8]\n",
            " [ 1 99]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_true = np.array([0] * 100 + [1] * 100)\n",
        "y_pred = probabilities > 0.5\n",
        "\n",
        "confusion_matrix_inceptionV3 = confusion_matrix(y_true, y_pred)\n",
        "print(confusion_matrix_inceptionV3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIOzFshYhmnP"
      },
      "source": [
        "## Quiz Question 6\n",
        "What's the validation accuracy based on y_pred?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjMWz1RchhAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf37211-7543-4870-a894-2e4bff02a5a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.955"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Your codes here\n",
        "############################################################\n",
        "np.trace(confusion_matrix_inceptionV3)/np.sum(confusion_matrix_inceptionV3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}