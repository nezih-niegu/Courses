{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHpZsRH_0F9A"
      },
      "source": [
        "First pull in the data from dropbox."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o-uNKXXz5OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cca5fd-a850-43c6-8168-b3f34db383d1"
      },
      "source": [
        "!wget https://www.dropbox.com/s/viz3bmc8cil4w1y/train_data.csv?dl=1\n",
        "!wget https://www.dropbox.com/s/07wu5by7llczd36/test_data.csv?dl=1\n",
        "!wget https://www.dropbox.com/s/80gdinsmalrrcll/sample_solution.csv?dl=1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-19 04:23:23--  https://www.dropbox.com/s/viz3bmc8cil4w1y/train_data.csv?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/viz3bmc8cil4w1y/train_data.csv [following]\n",
            "--2023-04-19 04:23:23--  https://www.dropbox.com/s/dl/viz3bmc8cil4w1y/train_data.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc2ec34981fb0dec39ba29049f80.dl.dropboxusercontent.com/cd/0/get/B6dLi9Jua8JzJWmnr5hDuUCugrKJwsSF8Zpw6Gh46NCO3O2IdCIfy0iVVJNDeAoXX76V6oC2x1bJGVVf4Nf0xRYvwarRBrkVcx-yO6P0t0zfjIQ8jLZSbKYC_YfQQGGH6grtWu5zs2jcinvXBGLZL9lxZbSkiW48dlnVbgW8CbcAKQ/file?dl=1# [following]\n",
            "--2023-04-19 04:23:24--  https://uc2ec34981fb0dec39ba29049f80.dl.dropboxusercontent.com/cd/0/get/B6dLi9Jua8JzJWmnr5hDuUCugrKJwsSF8Zpw6Gh46NCO3O2IdCIfy0iVVJNDeAoXX76V6oC2x1bJGVVf4Nf0xRYvwarRBrkVcx-yO6P0t0zfjIQ8jLZSbKYC_YfQQGGH6grtWu5zs2jcinvXBGLZL9lxZbSkiW48dlnVbgW8CbcAKQ/file?dl=1\n",
            "Resolving uc2ec34981fb0dec39ba29049f80.dl.dropboxusercontent.com (uc2ec34981fb0dec39ba29049f80.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc2ec34981fb0dec39ba29049f80.dl.dropboxusercontent.com (uc2ec34981fb0dec39ba29049f80.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19724914 (19M) [application/binary]\n",
            "Saving to: ‘train_data.csv?dl=1’\n",
            "\n",
            "train_data.csv?dl=1 100%[===================>]  18.81M  50.3MB/s    in 0.4s    \n",
            "\n",
            "2023-04-19 04:23:24 (50.3 MB/s) - ‘train_data.csv?dl=1’ saved [19724914/19724914]\n",
            "\n",
            "--2023-04-19 04:23:25--  https://www.dropbox.com/s/07wu5by7llczd36/test_data.csv?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/07wu5by7llczd36/test_data.csv [following]\n",
            "--2023-04-19 04:23:25--  https://www.dropbox.com/s/dl/07wu5by7llczd36/test_data.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc41d1d428323df2ac032689ab89.dl.dropboxusercontent.com/cd/0/get/B6cMWzs_L1McleuntlosTE13HpZcA7K7rCj6tePXHwgBfR1eprFWtMhJpKqpKVCObwzxDbjZ-ApjOURgxbqzGVUGACcCsVo6ZTCXyweOwzN_Agfh_lEh4c_HX_6YoqmK2ckWiGehsnkS3CxUiFZpgDcdPr0Xfufc5APi9Oc4uQaK0Q/file?dl=1# [following]\n",
            "--2023-04-19 04:23:25--  https://uc41d1d428323df2ac032689ab89.dl.dropboxusercontent.com/cd/0/get/B6cMWzs_L1McleuntlosTE13HpZcA7K7rCj6tePXHwgBfR1eprFWtMhJpKqpKVCObwzxDbjZ-ApjOURgxbqzGVUGACcCsVo6ZTCXyweOwzN_Agfh_lEh4c_HX_6YoqmK2ckWiGehsnkS3CxUiFZpgDcdPr0Xfufc5APi9Oc4uQaK0Q/file?dl=1\n",
            "Resolving uc41d1d428323df2ac032689ab89.dl.dropboxusercontent.com (uc41d1d428323df2ac032689ab89.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc41d1d428323df2ac032689ab89.dl.dropboxusercontent.com (uc41d1d428323df2ac032689ab89.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12332351 (12M) [application/binary]\n",
            "Saving to: ‘test_data.csv?dl=1’\n",
            "\n",
            "test_data.csv?dl=1  100%[===================>]  11.76M  32.5MB/s    in 0.4s    \n",
            "\n",
            "2023-04-19 04:23:26 (32.5 MB/s) - ‘test_data.csv?dl=1’ saved [12332351/12332351]\n",
            "\n",
            "--2023-04-19 04:23:26--  https://www.dropbox.com/s/80gdinsmalrrcll/sample_solution.csv?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/80gdinsmalrrcll/sample_solution.csv [following]\n",
            "--2023-04-19 04:23:27--  https://www.dropbox.com/s/dl/80gdinsmalrrcll/sample_solution.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc8a3cdc37af18697c31dbcc9b53.dl.dropboxusercontent.com/cd/0/get/B6e8f-mRyMEeKPnCuagjJkiozZHUUlg3chVu8Rhnh4ymSvTrCQ9dRi8P16Cqdxqaj7vJOnqhaaJOdyiqeeR0XimM-BDQzIdRlqq2o2gsWCeKyGDrMf3x5FzgdW0h7wQGChaVvcnIVoAjrMtvVXmEugnhqixNZRoEcBFyDaKEHp-Axg/file?dl=1# [following]\n",
            "--2023-04-19 04:23:27--  https://uc8a3cdc37af18697c31dbcc9b53.dl.dropboxusercontent.com/cd/0/get/B6e8f-mRyMEeKPnCuagjJkiozZHUUlg3chVu8Rhnh4ymSvTrCQ9dRi8P16Cqdxqaj7vJOnqhaaJOdyiqeeR0XimM-BDQzIdRlqq2o2gsWCeKyGDrMf3x5FzgdW0h7wQGChaVvcnIVoAjrMtvVXmEugnhqixNZRoEcBFyDaKEHp-Axg/file?dl=1\n",
            "Resolving uc8a3cdc37af18697c31dbcc9b53.dl.dropboxusercontent.com (uc8a3cdc37af18697c31dbcc9b53.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc8a3cdc37af18697c31dbcc9b53.dl.dropboxusercontent.com (uc8a3cdc37af18697c31dbcc9b53.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 789927 (771K) [application/binary]\n",
            "Saving to: ‘sample_solution.csv?dl=1’\n",
            "\n",
            "sample_solution.csv 100%[===================>] 771.41K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-04-19 04:23:28 (5.83 MB/s) - ‘sample_solution.csv?dl=1’ saved [789927/789927]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGIZiEGp27iu"
      },
      "source": [
        "**Read in the data**.\n",
        "\n",
        "First we will read in the files that have the training and testing data. We'll look at the first 5 rows to get a feel for what's inside:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSFQLIcM238v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9ad67f29-7eac-4384-c4b9-e6f75cfccfa6"
      },
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv('train_data.csv?dl=1', encoding = 'latin-1')\n",
        "test_data = pd.read_csv('test_data.csv?dl=1', encoding = 'latin-1')\n",
        "train_data.iloc[0:5]\n",
        "train_data.Text.iloc[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'From pvconway cudnvr denver colorado edu Subject TIN files coutours Lines 15 Hi I am working on a project that needs to create contour lines from random data points The work that I have done so far tells me that I need to look into Triangulated Irregular Networks TIN the Delauney criiterion and the Krige method Does anyone have any suggestions for references programs and hopefully source code for creating contours Any help with this or any surface modeling would be greatly appreciated I can be reached at the addresses below Paul Conway PVCONWAY COPPER DENVER COLORADO EDU PVCONWAY CUDNVR DENVER COLORADO EDU'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0XZ6nzM3pxF"
      },
      "source": [
        "**Preprocess the text**\n",
        "\n",
        "Now we'll process the text and convert the words to sequences of integers, keeping only the 10,000 most common words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_Y0Xus1D_1L"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "texts = train_data['Text']\n",
        "test_sentences = test_data['Text']\n",
        "labels = train_data['Label']\n",
        "\n",
        "# RNN specific\n",
        "max_words = 15000\n",
        "token = Tokenizer(max_words)\n",
        "token.fit_on_texts(texts)\n",
        "vocab_size = max_words + 1\n",
        "\n",
        "sequences = token.texts_to_sequences(texts)\n",
        "test_sequences = token.texts_to_sequences(test_sentences)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFUkAYhXluW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a149ee57-d8f9-4c53-de31-a5815b0c602e"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14,\n",
              " 2375,\n",
              " 567,\n",
              " 15,\n",
              " 29,\n",
              " 757,\n",
              " 364,\n",
              " 32,\n",
              " 211,\n",
              " 599,\n",
              " 8,\n",
              " 127,\n",
              " 587,\n",
              " 16,\n",
              " 4,\n",
              " 902,\n",
              " 10,\n",
              " 816,\n",
              " 2,\n",
              " 1048,\n",
              " 12264,\n",
              " 32,\n",
              " 14,\n",
              " 1726,\n",
              " 234,\n",
              " 716,\n",
              " 1,\n",
              " 175,\n",
              " 10,\n",
              " 8,\n",
              " 21,\n",
              " 378,\n",
              " 56,\n",
              " 319,\n",
              " 2302,\n",
              " 63,\n",
              " 10,\n",
              " 8,\n",
              " 174,\n",
              " 2,\n",
              " 255,\n",
              " 135,\n",
              " 13159,\n",
              " 3156,\n",
              " 757,\n",
              " 1,\n",
              " 6,\n",
              " 1,\n",
              " 1316,\n",
              " 108,\n",
              " 171,\n",
              " 21,\n",
              " 62,\n",
              " 1569,\n",
              " 12,\n",
              " 1628,\n",
              " 578,\n",
              " 6,\n",
              " 3032,\n",
              " 446,\n",
              " 413,\n",
              " 12,\n",
              " 3321,\n",
              " 62,\n",
              " 197,\n",
              " 22,\n",
              " 17,\n",
              " 25,\n",
              " 62,\n",
              " 1782,\n",
              " 9166,\n",
              " 48,\n",
              " 18,\n",
              " 1680,\n",
              " 1015,\n",
              " 8,\n",
              " 39,\n",
              " 18,\n",
              " 3094,\n",
              " 33,\n",
              " 1,\n",
              " 2532,\n",
              " 1117,\n",
              " 535,\n",
              " 7020,\n",
              " 2375,\n",
              " 567,\n",
              " 15,\n",
              " 2375,\n",
              " 567,\n",
              " 15]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zU5Zdmd4Bvz"
      },
      "source": [
        "**Pad the sequences**\n",
        "\n",
        "Next we 0-pad the sequences, and short sequences will have 0s prepended so that each sequence is exactly 100 integers long. Note long sentences will be trimmed so that only the first 100 words are used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtUnDIjPFwac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04022ca-b8c3-466d-85f5-788da51fd163"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "seq_len = 100\n",
        "X = pad_sequences(sequences, maxlen=seq_len)\n",
        "X_test = pad_sequences(test_sequences, maxlen=seq_len)\n",
        "print(X.shape)\n",
        "print(X[0])\n",
        "print(len(sequences[0]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11314, 100)\n",
            "[    0     0     0     0     0     0     0     0     0    14  2375   567\n",
            "    15    29   757   364    32   211   599     8   127   587    16     4\n",
            "   902    10   816     2  1048 12264    32    14  1726   234   716     1\n",
            "   175    10     8    21   378    56   319  2302    63    10     8   174\n",
            "     2   255   135 13159  3156   757     1     6     1  1316   108   171\n",
            "    21    62  1569    12  1628   578     6  3032   446   413    12  3321\n",
            "    62   197    22    17    25    62  1782  9166    48    18  1680  1015\n",
            "     8    39    18  3094    33     1  2532  1117   535  7020  2375   567\n",
            "    15  2375   567    15]\n",
            "91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN-UV8AF4aXD"
      },
      "source": [
        "**Make y one-hot**\n",
        "\n",
        "Now we will convert the label to a one-hot representation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQmnDlYjGE92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624e9df2-9a35-4482-aaf9-2ef20d06ef51"
      },
      "source": [
        "import numpy as np\n",
        "## Make y one-hot ##\n",
        "y = np.zeros( (len(labels), len(np.unique(labels)) ) )\n",
        "for l in np.unique(labels):\n",
        "    pos_inds = np.where(labels == l)[0]\n",
        "    y[pos_inds,l] = 1\n",
        "\n",
        "num_classes = y.shape[1]\n",
        "print(y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11314, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR6QbQiC7jGd"
      },
      "source": [
        "**Set up and train the RNN using the _functional_ API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1ZtMeLsGQ5I"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Embedding, Input, Dropout, LSTM\n",
        "\n",
        "num_timesteps = X.shape[1] #X.shape[0]=number of samples, and X.shape[1]=number of time steps\n",
        "\n",
        "## Functional API specific\n",
        "input = Input(shape=(num_timesteps, ))\n",
        "\n",
        "x = Embedding(input_dim = vocab_size, output_dim = 128, name='embedding')(input)\n",
        "x = LSTM(units = 128)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(units=20, activation='softmax', name='output')(x)\n",
        "\n",
        "model = Model(inputs=input, outputs=x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDHlE9YvX0m9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26850291-749b-40de-c35b-beaf3ace1881"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 100, 128)          1920128   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 20)                5140      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,089,876\n",
            "Trainable params: 2,089,876\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJiUBfMYLBd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d16cc1-657b-4b00-e9da-b37e1b10545d"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X,y,epochs=15, validation_split=0.2, batch_size = 256)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "36/36 [==============================] - 16s 228ms/step - loss: 2.9894 - accuracy: 0.0693 - val_loss: 2.9691 - val_accuracy: 0.0720\n",
            "Epoch 2/15\n",
            "36/36 [==============================] - 6s 158ms/step - loss: 2.8907 - accuracy: 0.1203 - val_loss: 2.6228 - val_accuracy: 0.1498\n",
            "Epoch 3/15\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 2.4402 - accuracy: 0.1852 - val_loss: 2.2491 - val_accuracy: 0.2391\n",
            "Epoch 4/15\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 1.9998 - accuracy: 0.2873 - val_loss: 1.9381 - val_accuracy: 0.3438\n",
            "Epoch 5/15\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 1.5451 - accuracy: 0.4432 - val_loss: 1.6406 - val_accuracy: 0.4565\n",
            "Epoch 6/15\n",
            "36/36 [==============================] - 4s 117ms/step - loss: 1.1627 - accuracy: 0.5785 - val_loss: 1.4784 - val_accuracy: 0.5232\n",
            "Epoch 7/15\n",
            "36/36 [==============================] - 4s 107ms/step - loss: 0.8703 - accuracy: 0.6875 - val_loss: 1.5194 - val_accuracy: 0.5510\n",
            "Epoch 8/15\n",
            "36/36 [==============================] - 3s 89ms/step - loss: 0.6958 - accuracy: 0.7566 - val_loss: 1.4125 - val_accuracy: 0.6023\n",
            "Epoch 9/15\n",
            "36/36 [==============================] - 3s 94ms/step - loss: 0.5248 - accuracy: 0.8131 - val_loss: 1.5358 - val_accuracy: 0.5957\n",
            "Epoch 10/15\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.4631 - accuracy: 0.8371 - val_loss: 1.5633 - val_accuracy: 0.6293\n",
            "Epoch 11/15\n",
            "36/36 [==============================] - 3s 99ms/step - loss: 0.3830 - accuracy: 0.8684 - val_loss: 1.6615 - val_accuracy: 0.6363\n",
            "Epoch 12/15\n",
            "36/36 [==============================] - 2s 64ms/step - loss: 0.2634 - accuracy: 0.9121 - val_loss: 1.6573 - val_accuracy: 0.6416\n",
            "Epoch 13/15\n",
            "36/36 [==============================] - 2s 60ms/step - loss: 0.2001 - accuracy: 0.9372 - val_loss: 1.7158 - val_accuracy: 0.6752\n",
            "Epoch 14/15\n",
            "36/36 [==============================] - 4s 105ms/step - loss: 0.1448 - accuracy: 0.9587 - val_loss: 1.8929 - val_accuracy: 0.6659\n",
            "Epoch 15/15\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 0.1393 - accuracy: 0.9579 - val_loss: 1.9606 - val_accuracy: 0.6496\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45700c4ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlHe0DteSX5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16800743-012e-4c2e-b225-2131dd1789d8"
      },
      "source": [
        "test_preds = model.predict(X_test, batch_size=256)\n",
        "submission_template = pd.read_csv('sample_solution.csv?dl=1')\n",
        "\n",
        "for j in range(test_preds.shape[1]):\n",
        "  submission_template.iloc[:,j+1] = test_preds[:,j]\n",
        "\n",
        "submission_template.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-52c91f33b0d3>:5: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  submission_template.iloc[:,j+1] = test_preds[:,j]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNOtV43N7Y-Y"
      },
      "source": [
        "**Download the submission and submit it to Kaggle**\n",
        "\n",
        "Download your predictions and submit them to the [kaggle](https://www.kaggle.com/c/bmi-707-rnn/) leaderboard!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBfwjqSLTBwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "874fa84e-5823-48fa-a111-d9b2003a05cf"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_25a72726-d1d5-4e08-be32-f8df40d29fdf\", \"submission.csv\", 2024806)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4MP1sKbHcui"
      },
      "source": [
        "**Possible Modifications**\n",
        "\n",
        "- More LSTM layers\n",
        "- Use a GRU instead of an LSTM\n",
        "- Use dropout within the LSTM - carefully read the [docs](https://keras.io/layers/recurrent/#lstm) how to do this, it's different than normal dropout.\n",
        "- Add a dense layer after the LSTM\n",
        "- Change the dimension of the embedding layer\n",
        "- Change the preprocessing steps (sequence length, vocab size, etc)\n",
        "- Try [bidirectional](https://keras.io/layers/wrappers/#bidirectional) units"
      ]
    }
  ]
}